{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the raw data ready to pocess, to csv file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting all the files from the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files():\n",
    "    all_file_path = []\n",
    "    \"\"\"walk through the data dir to its sub-dirs and gets all the file with .review extension and return all the file_paths list\"\"\"\n",
    "    # looping through the directory and the sub-directory\n",
    "    for root, dirs, files in os.walk(\"data\"):\n",
    "        for file in files:\n",
    "            # getting the file end with .review\n",
    "            if file.endswith(\".review\"):\n",
    "                # joining the file path with the actual full path of the file \n",
    "                file_path = os.path.join(root, file)\n",
    "                # appending the file_path in the list \n",
    "                all_file_path.append(file_path)\n",
    "    return all_file_path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorized the files into list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_files(all_file_path):\n",
    "    \"\"\"get all file path and categorised the files into positive, negative and unlabeled review and return the file path list as tuple\"\"\"\n",
    "    \n",
    "    pos_review_f_path = []\n",
    "    neg_review_f_path=[]\n",
    "    unl_review_f_path = []\n",
    "    \n",
    "    for file in all_file_path:\n",
    "        if \"positive\" in file:\n",
    "            pos_review_f_path.append(file)\n",
    "        elif \"negative\" in file:\n",
    "            neg_review_f_path.append(file)\n",
    "        else:\n",
    "            unl_review_f_path.append(file)\n",
    "    return pos_review_f_path, neg_review_f_path, unl_review_f_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"reads the file from file path and return all lines in list\"\"\"\n",
    "    with open(file_path) as file:\n",
    "        items = file.readlines()\n",
    "    return items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making the list of review after reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_review_list(items):\n",
    "    \"\"\"gets all the items, prepare a list of each review and returns the list of reviews\"\"\"\n",
    "    reviews = []\n",
    "    review = []\n",
    "    for item in items:\n",
    "        # remove \\n from the item\n",
    "        item = item[:-1]\n",
    "        # get the file inside the review block not including the start and the end block\n",
    "        if item != '<review>' and item != '</review':\n",
    "            review.append(item)\n",
    "            \n",
    "        #  adding the review to the review list  \n",
    "        if item == '</review>':\n",
    "            reviews.append(review)\n",
    "            review = []\n",
    "    return reviews\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing the review and making it ready to transfer into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review_list(list_of_reviews):\n",
    "    \"\"\"gets the list of reviews, seperate the headings and values and returns as list of dictionary\"\"\"\n",
    "    dict_review_list = []\n",
    "    previous_key = None\n",
    "    \n",
    "    #iterating through reviews\n",
    "    for review in (list_of_reviews):\n",
    "        dict_review = {}\n",
    "        #iterating through a single review\n",
    "        for num, item in enumerate(review):\n",
    "            #eliminating null values\n",
    "            if item != \"\":\n",
    "                #getting and heading and assigning with corresponding values\n",
    "                if item[0] ==\"<\" and item[1] != \"/\":\n",
    "                    dict_review[item] = review[num + 1]\n",
    "                    previous_key = item\n",
    "                #checking if any values are missing and reassigning them\n",
    "                if item not in dict_review.values() and item[0] != '<':\n",
    "                    dict_review[previous_key] += item\n",
    "        # when a review is ready adding it to the list\n",
    "        dict_review_list.append(dict_review)\n",
    "    return dict_review_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting the list of the dict into the datarame to convert into the csv file or process straightly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the data from list of dict using lambda\n",
    "to_dataframe = lambda list_of_dict: pd.DataFrame(list_of_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting the dataframe into the csv file and saving into the directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and save to csv file\n",
    "save_to_csv = lambda df, file_name: df.to_csv(file_name, index=False, encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining all the process to get single list of review of each category file found in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_csv():\n",
    "    dir = os.path.abspath(os.getcwd()) + \"/data/csv_files/\"\n",
    "    \n",
    "    file_name = ('positive_review', 'negative_review', 'unlabled_review')\n",
    "\n",
    "    # get all the files\n",
    "    all_file_path = get_files()\n",
    "    \n",
    "    #categorised the files in the list\n",
    "    categories = categorise_files(all_file_path)\n",
    "    \n",
    "    #read all the files from each category:\n",
    "    for num, category in enumerate(categories):\n",
    "        \n",
    "        # hold all the items of each category in one list \n",
    "        items_holder = []\n",
    "        \n",
    "        for file_path in category:\n",
    "            # getting all the items\n",
    "            items = read_file(file_path)\n",
    "            items_holder.extend(items)\n",
    "        \n",
    "        # build the list of the items in one category\n",
    "        list_of_reviews = build_review_list(items_holder)\n",
    "        \n",
    "        # buid of list of processed review in dictionaries\n",
    "        list_of_dict_reviews = process_review_list(list_of_reviews)\n",
    "        \n",
    "        # build of dataframe from processed_list\n",
    "        data_frame = to_dataframe(list_of_dict_reviews)\n",
    "        \n",
    "        # save the dataframe into the csv file\n",
    "        save_to_csv(data_frame, file_name=(dir + file_name[num]))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv\n",
    "convert_to_csv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for pandas\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening  csv file\n",
    "open_review = lambda file: pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = open_review(\"./data/csv_files/positive_review\")\n",
    "df_negative = open_review(\"./data/csv_files/negative_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unique id and make asin as a unique id\n",
    "# remove the unwanted text from product name\n",
    "# in helpful column make the data in fractions or ratio to represent mathmatically\n",
    "# convert the date column into the date type\n",
    "# remove the unwanted text from the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process to follow\n",
    "\n",
    "# process the positive review file\n",
    "# process the negative review file\n",
    "# merge the both file \n",
    "# randomised the data\n",
    "# split the data into train, evaluation and test data\n",
    "# train the model \n",
    "# evaluate the model\n",
    "# test the model\n",
    "# dump the model into the file so that we don't have to train the new model time to time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;unique_id&gt;</th>\n",
       "      <th>&lt;asin&gt;</th>\n",
       "      <th>&lt;product_name&gt;</th>\n",
       "      <th>&lt;product_type&gt;</th>\n",
       "      <th>&lt;helpful&gt;</th>\n",
       "      <th>&lt;rating&gt;</th>\n",
       "      <th>&lt;title&gt;</th>\n",
       "      <th>&lt;date&gt;</th>\n",
       "      <th>&lt;reviewer&gt;</th>\n",
       "      <th>&lt;reviewer_location&gt;</th>\n",
       "      <th>&lt;review_text&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>B000EP5MOA:excellent_ipod,_my_favorite_so_far.:</td>\n",
       "      <td>B000EP5MOA</td>\n",
       "      <td>Apple 4 GB iPod Nano Green (2nd Generation)</td>\n",
       "      <td>electronics</td>\n",
       "      <td>7 of 7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Excellent iPod, my favorite so far.</td>\n",
       "      <td>November 22, 2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love the new nanos. I don't think I have any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>B00001P4ZD:fits_my_fat_head...:</td>\n",
       "      <td>B00001P4ZD</td>\n",
       "      <td>Koss KTX-Pro Portable Stereophone</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1 of 2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Fits my fat head...</td>\n",
       "      <td>August 21, 2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I stretched them till they fit comfortably on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>B00000J0O2:it_does_the_job:</td>\n",
       "      <td>B00000J0O2</td>\n",
       "      <td>HP Microfine Toner Cartridge for LaserJet 5L/6...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>3 of 3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It does the job</td>\n",
       "      <td>June 20, 2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Well the most important thing about buying ink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>B000058E2B:why_i_still_like_this_pda,_continued:</td>\n",
       "      <td>B000058E2B</td>\n",
       "      <td>Compaq iPAQ 3635 Pocket PC Bundle (with Compac...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Why I still like this PDA, continued</td>\n",
       "      <td>April 4, 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I found out the way to copy photos from my Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>B00003CWE5:buy_these_cables!:</td>\n",
       "      <td>B00003CWE5</td>\n",
       "      <td>Monster Cable MV2CV-1M Monster Video 2 Compone...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>4 of 12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Buy these cables!</td>\n",
       "      <td>March 15, 2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These cables are super with my new DVD player....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          <unique_id>      <asin>                                     <product_name> <product_type> <helpful>  <rating>                               <title>             <date> <reviewer> <reviewer_location>                                      <review_text>\n",
       "238   B000EP5MOA:excellent_ipod,_my_favorite_so_far.:  B000EP5MOA        Apple 4 GB iPod Nano Green (2nd Generation)    electronics    7 of 7       5.0   Excellent iPod, my favorite so far.  November 22, 2006        NaN                 NaN  I love the new nanos. I don't think I have any...\n",
       "316                   B00001P4ZD:fits_my_fat_head...:  B00001P4ZD                  Koss KTX-Pro Portable Stereophone    electronics    1 of 2       4.0                   Fits my fat head...    August 21, 2002        NaN                 NaN  I stretched them till they fit comfortably on ...\n",
       "433                       B00000J0O2:it_does_the_job:  B00000J0O2  HP Microfine Toner Cartridge for LaserJet 5L/6...    electronics    3 of 3       5.0                       It does the job      June 20, 2000        NaN                 NaN  Well the most important thing about buying ink...\n",
       "438  B000058E2B:why_i_still_like_this_pda,_continued:  B000058E2B  Compaq iPAQ 3635 Pocket PC Bundle (with Compac...    electronics       NaN       4.0  Why I still like this PDA, continued      April 4, 2004        NaN                 NaN  I found out the way to copy photos from my Com...\n",
       "532                     B00003CWE5:buy_these_cables!:  B00003CWE5  Monster Cable MV2CV-1M Monster Video 2 Compone...    electronics   4 of 12       5.0                     Buy these cables!     March 15, 2001        NaN                 NaN  These cables are super with my new DVD player...."
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can replace the nan reviewer to \"Anonymous User\" to say these person does not want to disclose their names on reviews\n",
    "# it can be possible that the reviewer doesn't have amazon account, or he posted anonymoulsly or there is an technical issues in the database\n",
    "df_positive.loc[df_positive['<reviewer>'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like all the nan reviewer also has nan values in the location table,\n",
    "# which can also provides more clarity that, the order without creating the amazon accounts\n",
    "# or they have incomplete account setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate the ':electronics' from the product name column values\n",
    "df_positive['<product_name>'] = df_positive['<product_name>'].str.partition(\":\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B00083LFSU:great:malachite'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#working with the unique id and the reviewer\n",
    "df_positive['<unique_id>'][98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unique_id>              0\n",
       "<asin>                   0\n",
       "<product_name>           0\n",
       "<product_type>           0\n",
       "<helpful>              467\n",
       "<rating>                 0\n",
       "<title>                  0\n",
       "<date>                   1\n",
       "<reviewer>              81\n",
       "<reviewer_location>    723\n",
       "<review_text>            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_negative.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Model Ready"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
